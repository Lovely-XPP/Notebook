\chapter{SLAM 简介}
\section{SLAM 的目标}
\thispagestyle{empty}
\dy{SLAM}{SLAM} 的全称为 Simultaneous Localization and Mapping，中文翻译为即时定位于建图，所以SLAM的目标就是两个：

\noa[1] 我在什么地方？——\dy{定位}{DW}
\noa[2] 周围环境怎么样？——\dy{建图}{JT}

\section{视觉 SLAM}
\subsection{SLAM 传感器}
机器的定位有两类传感器。

\noa[1] \textbf{机器本身携带}：轮式编码器、相机、激光传感器、IMU等
\noa[2] \textbf{安装于环境}：导轨、二维码标识等

由于环境中的传感器受限于环境的条件，而GPS在室内没有信号，SLAM就是为了解决在任意未知环境中进行定位。这里主要讲视觉SLAM的工作。

\subsection{视觉SLAM的传感器}

视觉SLAM主要的传感器就是\textbf{相机}，照片本质上是场景在相机的成像平面上的\textbf{投影}。它以\textbf{二维的形式记录了三维的世界}，在这个过程中丢掉了场景的一个维度：\dy{深度}{SD}（距离）。相机主要有三类：

\nob[1] \dy{单目相机}{DMXJ}
\begin{itemize}[itemsep=0.1pt,topsep =2pt]
    \item 组成：只使用一个摄像头。
    \item 原理：在单张图像中，无法确定一个物体的真实大小。它可能是一个\textbf{很大但很远}的物体，也可能是一个\textbf{很近但很小}的物体。所以如果要恢复三维结构，只能改变相机的视角。所以在单目SLAM中，我们必须移动相机才能估计它的\dy{运动}{YD}（Motion），同时估计场景中物体的远近和大小，称为\dy{结构}{JG}（Structure）。从图像的变化可以得到相机的相对运动状态，同时我们还知道：\textbf{近处的物体移动块，远处的物体移动慢，极远处（无穷远处）的物体（如太阳、月亮）看上去是不动的}。所以物体在图像上的运动就形成了\dy{视差}{SC}（Disparity），通过视差就可以定量判断物体的距离远近。
    \item 缺点：由于单张图像无法确定深度，所以得到的物体远近仅仅是一个相对值。也就是说，如果把相机的运动和场景放大同样的倍数，单目相机得到的像是一样的。所以，单目SLAM估计的轨迹和地图将与真实的轨迹和地图相差一个因子，即\dy{尺度}{CD}（Scale）。由于单目SLAM无法仅仅通过图像确定真实尺度，所以又称为\dy{尺度不确定性}{CDBQDX}（Scale Ambiguity）。
\end{itemize}
\vspace*{0.5em}

\nob[2] \dy{双目相机}{SMXJ}
\begin{itemize}[itemsep=0.1pt,topsep =2pt]
    \item 目的：通过某种手段测量物体与相机之间的距离，克服单目相继无法知道距离的缺点。
    \item 组成：两个单目相机，且两个相机之间的距离（\dy{基线}{JX}）已知。
    \item 原理：和人眼相似，通过左右眼图像的差异判断物体的远近，具体定量用基线确定。
    \item 缺点：需要大量计算才能近似（不太可靠）估计每一个像素点的深度，且深度的量程和精度受基线和分辨率所限，视差的计算需要消耗大量的计算资源。
    \item 应用：室内室外
\end{itemize}

\vspace*{0.5em}

\nob[3] \dy{深度相机}{SDXJ}
\begin{itemize}[itemsep=0.1pt,topsep =2pt]
    \item 目的：通过某种手段测量物体与相机之间的距离，克服单目相继无法知道距离的缺点。
    \item 组成：深度相机又称 \dy{RGB-D相机}{RGBDXJ}，由激光传感器等组成。
    \item 原理：通过红外结构光或Time-of-Flight（ToF）原理，像激光传感器那样，主动向物体发射并接受返回的光，测出物体与相机的距离，此为通过物理测量手段进行测量，可以节省大量的计算资源。
    \item 缺点：测量范围窄、噪声大、视野小、易受日光干扰、无法测量透射物质。
    \item 应用：室内
\end{itemize}

\section{经典的视觉SLAM框架}
\begin{figure}[!htp]
    \centering
    \begin{tikzpicture}
        \node(A) [draw,inner sep=3pt] {\makecell{传感器\\[-0.2em] \hspace*{1em}信息读取\hspace*{1em}}};
        \node(B) [draw,right of = A, node distance = 4cm, inner sep=3pt] {\makecell{前端\\[-0.2em] \hspace*{1em}视觉里程计\hspace*{1em}}};
        \node(C) [draw,right of = B, node distance = 4cm, inner sep=3pt] {\makecell{后端\\[-0.2em] \hspace*{1em}非线性优化\hspace*{1em}}};
        \node(D) [draw,right of = C, node distance = 4cm, inner sep=3pt] {\makecell{\hspace*{1em}建图\hspace*{1em}}};
        \node(E) [draw,below of = B, node distance = 2cm, inner sep=3pt] {\makecell{\hspace*{1em}回环检测\hspace*{1em}}};

        %\draw[arrows={-Stealth}](0cm,1.5cm) -- (D)  node[midway,right = 0.5cm, above=0cm]{干扰};
        \draw[arrows={-Stealth}] (A) -- (B);
        \draw[arrows={-Stealth}] (B) -- (C);
        \draw[arrows={-Stealth}] (C) -- (D);
        \draw[arrows={-Stealth}] (A) -- +(0cm,-2cm) -- (E) -- +(4cm,0cm) --(C);
    \end{tikzpicture}
    \caption{经典的视觉SLAM框架}
    \label{SLAM Frame}
\end{figure}

如图 \ref{SLAM Frame} 所示，经典的视觉SLAM框架包括以下几个流程。
\begin{enumerate}
    \setlength{\leftmargin}{1.2em} %左边界
    \setlength{\parsep}{0ex} %段落间距
    \setlength{\topsep}{0.5ex} %列表到上下文的垂直距离
    \setlength{\itemsep}{0.2ex} %条目间距
    \setlength{\labelsep}{0.5em} %标号和列表项之间的距离,默认0.5em
    \setlength{\itemindent}{0.5em} %标签缩进量
    \setlength{\listparindent}{0em} %段落缩进量

    \item \dy{传感器信息读取}{CGQXXDQ}：相机图像信息的读取和预处理。在机器人中，还可能包括码盘、惯性传感器等信息的读取和同步。
    \item \dy{前端视觉里程计}{QDSJLCJ}（Visual Odometery，\dy{VO}{VO}）：估算相邻图像间相机运动，以及局部地图的样子。VO 又称为\dy{前端}{QD}（Front End）。
    \item \dy{后端非线性优化}{HDFXXYH}（Optimization）：接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图。由于接在VO之后，又称为\dy{后端}{HD}（Back End）。
    \item \dy{回环检测}{HHJC}（Loop Closure Detection）：回环检测判断机器人是否到达过先前的位置。如果检测到回环，它会把信息提供给后端进行处理。
    \item \dy{建图}{JT}：根据估计的轨迹，建立与任务要求对应的地图。
\end{enumerate}

\newpage

\textbf{在静态、刚体、光照变化不明显、没有人为干扰的场景下}，视觉SLAM技术已经相当成熟。

\subsection{视觉里程计}
视觉里程计是通过\textbf{相邻帧间的图像估计相机运动}，再通过\textbf{相机与空间点的几何关系}来估计当前时刻的相机运动，然后将相邻时刻的运动“串起来”，可以估计任意时刻的相机运动并恢复整个场景的空间结构。它称为“里程计”是因为它和实际的里程计一样，只计算相邻时刻的运动（不限于2帧，可以是5 $\sim$ 10 帧），而和过去的信息没有关联。

但是，由于视觉里程计在最简单的情况下只估计极少量图像间的运动，每个时刻的估计都产生一定的误差，导致先前的误差会传递到下一时刻，误差会随时间不断累积，这就是\dy{累积漂移}{LJPY}（Accumulating Drift）。这将导致无法建立一致的地图。为了解决漂移问题，我们还需要后端优化和回环检测。回环检测负责吧“机器人回到原始位置”的事情检测出来，而后端优化则根据该信息，校正整个轨迹的形状。

\subsection{后端优化}
后端优化主要指助理SLAM过程中的\textbf{噪声}问题。任何传感器都会带一定的噪声，为此我们需要估计传感器带有多大的噪声，这些噪声是如何从上一时刻传递到下一时刻的，而我们又对当前的估计有多大的自信。后端优化要考虑的问题就是如何从这些带有噪声的数据中估计整个系统的状态，以及这个状态轨迹的不确定性有多大——这称为\dy{最大后验概率估计}{ZDHYGLGJ}（Maximum-a-Posteriori, MAP）。这里的状态既包括机器人自身的轨迹，也包含地图。

前端给后端提供待优化的数据，后端只关心数据而不关心数据来自哪里。\textbf{在视觉SLAM中，前端和计算机视觉研究更为相关，比如图像的特征提取与匹配等，后端则主要是滤波与非线性算法}。

后端：借助状态估计理论，把定位和建图的不确定性表达出来，然后采用滤波器或非线性优化，估计状态的均值和不确定性（方差）。

\subsection{回环检测}
回环检测又称闭环检测，主要解决\textbf{位置估计随时间漂移}的问题。这需要让机器人具有\textbf{识别到过的场景}的能力。视觉SLAM 一般采用\textbf{判断图像间的相似性}的方法来完成回环检测。所以视觉回环检测实质上是一种计算图像数据相似性的算法。机器人判断回到原点后，将数据重新更新为当时不含累积漂移的数据，同时后端根据这些新的信息，把轨迹和地图调整到符合回环检测结果的样子。所以，如果我们又充分而且正确的回环检测，则可以消除累积误差，得到全局一致的轨迹和地图。

\subsection{建图}
建图是指构件\dy{地图}{DT}的过程。地图是对环境的描述，但这个描述并不是固定的，需要视SLAM的应用而定。大体上讲，地图可以分为\textbf{度量地图}和\textbf{拓扑地图}两种。

\nob[1] \dy{度量地图}{DMXJ}\textbf{（Metric Map）}

度量地图强调精确地表示地图中物体的位置关系，通常用稀疏（Sparse）与稠密（Dense）对其分类。
\begin{itemize}[itemsep=0.1pt,topsep =2pt]
    \item \dy{稀疏地图}{XSDT}：稀疏地图进行了一定程度的抽象，并不需要表达所有物体。例如，我们选择一部分具有代表意义的东西，称之为\dy{路标}{LB}（Landmark），那么一张稀疏地图就是由路标组成的地图，而不是路标的部分就可以忽略。
    \item \dy{稠密地图}{CMDT}：稠密地图着重于建模所有看到的东西。稠密地图通常按照某种分辨率，由许多个小块组成，在二维度量地图中体现为许多个小\dy{格子}{GZ}（Grid），而在三维度量地图中则体现为许多小\dy{方块}{FK}（Voxel）。通常一个小块含有占据、空间、未知三种状态，以表达该格内是否有物体。当查询某个空间位置时，地图能够给出该位置是否可以通过的信息。一般导航就是使用稠密地图。缺点：耗费大量储存空间且很多细节是不需要的，而且大规模度量地图可能会出现一致性问题，很小的误差就可以导致物体重叠，使地图失效。
\end{itemize}
\vspace*{1em}

\nob[2] \dy{拓扑地图}{TPDT}\textbf{（Topological Map）}

相比于度量地图的精确性，拓扑地图更强调地图元素之间的关系。拓扑地图是一个\dy{图}{T}（Graph），由节点和边组成，只考虑节点之间的连通性，而不关注节点之间是如何连通的。

优点：放松了地图对精确位置的需要，去掉了地图的细节，表达更紧凑。

缺点：不擅长表达具有复杂结构的地图，如何将实际地图转换为拓扑地图，如何使用拓扑地图进行导航与路径规划，都是比较困难的。



\section{SLAM 问题的数学表达}
假设一个机器人携带一些传感器在位置环境里面运动。由于传感器是离散采样，记采样的时刻为（连续时间离散化）$t = 1, \cdots ,K$，机器人在各个时刻的位置记为$\bm{x}_1 , \cdots, \bm{x}_K$。假设地图是由许多个\textbf{路标}组成的，传感器在各个时刻测量到一部分路标点。假设路标点一共有$N$个，记为$\bm{y}_1, \cdots, \bm{y}_N$。

我们需要描述的两个问题：运动与观测。

\subsection{运动的数学表达}
什么是运动？即考察$k-1 \to k$时刻，机器人位置$\bm{x}$的变化情况。机器人的运动状况是由上一个时刻的位置$\bm{x}_{k-1}$以及运动传感器的读数或输入$\bm{u}_k$，当然只要是传感器都会有噪声，所以噪声$\bm{\omega}_k$也会对当前时刻的位置造成影响。综上，我们可以用一个函数来表示通用、抽象的数学模型。

\defination{运动方程}
{
    \dy{运动方程}{YDFC}定义如下：
    \begin{equation}
        \bm{x}_k = f(\bm{x}_{k-1}, \bm{u}_k, \bm{\omega}_k)
    \end{equation}
}

噪声的存在使得这个模型变成了随机模型。因为每次运动过程中的噪声是随机的，如果忽略噪声的影响，只根据指令来估计位置，可能与实际位置相差很远。

\subsection{观测的数学表达}
什么是观测？即考察在$k$时刻时机器人在$\bm{x}_k$处观测到了某一个路标$\bm{y}_j$，如何描述这个事件。同样地，我们可以用一个抽象的函数来表示这个数学模型。

\defination{观测方程}
{
    \dy{观测方程}{GCFC}定义如下：
    \begin{equation}
        \bm{z}_{k,j} = h (\bm{y}_j, \bm{x}_k, \bm{v}_{k,j})
    \end{equation}
}
其中，$\bm{v}_{k,j}$是观测中的噪声。


\subsection{参数化实例}
对于不同的真实运动和传感器种类，存在很多\dy{参数化}{CSH}（Parameterization）方式。例如，假设机器人在平面内运动，那么它的位姿（位置和姿态）由两个位置参数和一个转角参数来描述，即
\begin{equation}
    \bm{x}_k = 
    \begin{bmatrix}
        x_1 \\
        x_2 \\
        \theta
    \end{bmatrix}_k
\end{equation}
其中，$x_1,x_2$为两个轴上的位置，而$\theta$为转角。同时，输入的指令是由两个时间间隔位置和转角的变化量来描述，即
\begin{equation}
    \bm{u}_k =
    \begin{bmatrix}
        \Delta x_1 \\
        \Delta x_2 \\
        \Delta \theta
    \end{bmatrix}_k
\end{equation}
于是运动凡尘就可以具体化为
\begin{equation}
    \begin{bmatrix}
        x_1 \\
        x_2 \\
        \theta
    \end{bmatrix}_k
    =
    \begin{bmatrix}
        x_1 \\
        x_2 \\
        \theta
    \end{bmatrix}_{k-1}
    +
    \begin{bmatrix}
        \Delta x_1 \\
        \Delta x_2 \\
        \Delta \theta
    \end{bmatrix}_k
    + \bm{\omega}_k
\end{equation}
在这种情况下，运动方程就是简单的线性关系。但是，不是所有输入指令都是位移和角度的变化量。例如“油门”或“控制杆”的输入就是速度或加速度量，所以运动方程是多样化的，具体需要进行动力学分析。

关于观测方程，以二维激光传感器为例。激光传感器观测2D路标时能够测量两个量：路标点与机器人之间的距离$r$和夹角$\phi$。记路标点，位姿和观测数据分别为
\begin{equation}
    \bm{y}_j = 
    \begin{bmatrix}
        y_1 \\
        y_2
    \end{bmatrix}_j
    \qquad
    \bm{x}_k =
    \begin{bmatrix}
        x_1 \\
        x_2
    \end{bmatrix}_k
    \qquad
    \bm{z}_{k,j} =
    \begin{bmatrix}
        r_{k,j} \\
        \phi_{k,j}
    \end{bmatrix}
\end{equation}
那么观测方程可以写为
\begin{equation}
    \begin{bmatrix}
        r_{k,j} \\
        \phi_{k,j}
    \end{bmatrix}
    =
    \begin{bmatrix}
        \sqrt{(y_{1,j} - x_{1,k})^2 + (y_{2,j} - x_{2,k})^2}\\
        \arctan \left(\dfrac{y_{2,j} - x_{2,k}}{y_{1,j} - x_{1,k}}\right)
    \end{bmatrix}
    + \bm{v}_{k,j}
\end{equation}

考虑视觉SLAM时，传感器是相机，那么观测方程就是“对路标点拍摄后，得到图像中的像素”的过程。

所以，针对不同的传感器，运动方程和观测方程有不同的参数化形式。如果我们保持通用性，把它们取成通用的抽象形式，那么SLAM过程可总结为两个基本方程。

\defination{SLAM 基本方程}
{
    SLAM 的两个基本方程为：
    \begin{equation}
        \begin{cases}
            \, \bm{x}_k = f(\bm{x}_{k-1}, \bm{u}_k, \bm{\omega}_k) & k = 1,\cdots, K \\
            \, \bm{z}_{k,j} = h(\bm{y}_j, \bm{x}_k, \bm{v}_{k,j}) & (k,j) \in \mathcal{O}
        \end{cases}
    \end{equation}
    其中，$\mathcal{O}$是一个集合，记录这在哪个时刻观察到了哪个路标，通常不是每个路标在每个时刻都能看到的——我们在单个时刻很可能只看到一小部分。
}

这两个方程描述了最基本的SLAM问题：当制导运动测量的读数$\bm{u}$，以及传感器的读数$\bm{z}$时，如何求解定位问题（估计$\bm{x}$）和建图问题（估计$\bm{y}$）？这是我们就把SLAM问题建模成了一个\textbf{状态估计问题}：如何通过带有噪声的测量数据，估计内部的、隐藏着的状态变量。

\subsection{问题总结}
\begin{figure}[!htb]
    \centering
    \begin{tikzpicture}
        \node(A) [draw,inner sep=5pt] {
        $
            \begin{cases}
                \, \bm{x}_k = f(\bm{x}_{k-1}, \bm{u}_k, \bm{\omega}_k) & k = 1,\cdots, K \\
                \, \bm{z}_{k,j} = h(\bm{y}_j, \bm{x}_k, \bm{v}_{k,j}) & (k,j) \in \mathcal{O}
            \end{cases}
        $};
        \node (B1) [draw, inner sep=5pt, below of = A, node distance = 3cm, xshift=-4cm]{方程具体形式};
        \node (B2) [draw, inner sep=5pt, below of = A, node distance = 3cm,xshift=4cm]{噪声分布形式};
        \node (D1) [draw, inner sep=5pt, below of = B1, node distance = 2cm, xshift=-2cm]{线性};
        \node (D2) [draw, inner sep=5pt, below of = B1, node distance = 2cm, xshift=1.8cm]{非线性};
        \node (D3) [draw, inner sep=5pt, below of = B2, node distance = 2cm, xshift=-2cm]{高斯分布};
        \node (D4) [draw, inner sep=5pt, below of = B2, node distance = 2cm, xshift=1.9cm]{非高斯分布};
        \node (E1) [draw, inner sep=5pt, below of = B1, node distance = 5cm]{\makecell{\dy{线性高斯系统}{XXGSXT}\\[-0.2em](Linear Gaussian, \dy{LG系统}{LGXT})}};
        \node (E2) [draw, inner sep=5pt, below of = B2, node distance = 5cm]{\makecell{\dy{非线性非高斯系统}{FXXFGSXT}\\[-0.2em](Non-Linear Non-Gaussian, \dy{NLNG系统}{NLNGXT})}};
        \node (F1) [draw, inner sep=5pt, below of = E1, node distance = 3cm] {\makecell{\dy{卡尔曼滤波器}{KEMLBQ}\\[-0.2em](Kalman Filter, \dy{KF}{KF})}};
        \node (F2) [draw, inner sep=5pt, below of = E2, node distance = 3cm, xshift = -3cm] {\makecell{\dy{扩展卡尔曼滤波器}{KZKEMLBQ}\\[-0.2em](Extended Kalman Filter, \dy{EKF}{EKF})}};
        \node (F3) [draw, inner sep=5pt, below of = E2, node distance = 3cm, xshift = 3cm] {\makecell{\dy{非线性优化}{FXXYH}\\[-0.2em](Nonlinear Optimization, \dy{NLO}{NLO})}};
        \node (G1) [draw, inner sep=5pt, below of = F2, node distance = 3cm] {\makecell{\dy{粒子滤波器}{LZLBQ}\\[-0.2em](Particle Filter)}};
        \node (G2) [draw, inner sep=5pt, below of = F3, node distance = 3cm] {\makecell{\dy{图优化}{TYH}\\[-0.2em](Graph Optimization)}};
        \node (H)[draw, inner sep=5pt, below of=G1, node distance = 1.8cm, xshift=0.5cm] {\large \textbf{最优状态估计问题}};

        %\draw[arrows={-Stealth}](0cm,1.5cm) -- (D)  node[midway,right = 0.5cm, above=0cm]{干扰};
        \draw (A) -- (0cm, -1.8cm);
        \draw[arrows={-Stealth}] (0cm, -1.8cm) --+ (-4cm, 0cm) -- (B1);
        \draw[arrows={-Stealth}] (0cm, -1.8cm) --+ (4cm, 0cm) -- (B2);
        \draw (B1) -- +(0cm, -1cm) -- +(-2cm,-1cm) -- (D1);
        \draw (B1) -- +(0cm, -1cm) -- +(1.8cm,-1cm) -- (D2);
        \draw (B2) -- +(0cm, -1cm) -- +(-2cm,-1cm) -- (D3);
        \draw (B2) -- +(0cm, -1cm) -- +(1.9cm,-1cm) -- (D4);
        \draw [blue,arrows={-Stealth}] (D1) -- +(0cm, -1.3cm) --+ (2cm, -1.3cm) -- (E1);
        \draw [blue,arrows={-Stealth}] (D3) -- +(0cm, -1.3cm) --+ (-6cm, -1.3cm) -- (E1);
        \draw [red,arrows={-Stealth}] (D2) -- +(0cm, -1cm) --+ (6.2cm, -1cm) -- (E2);
        \draw [red,arrows={-Stealth}] (D4) -- +(0cm, -1cm) --+ (-1.9cm, -1cm) -- (E2);
        \draw (E1) -- (F1);
        \draw (E2) -- +(0cm, -1.5cm) -- +(-3cm,-1.5cm) -- (F2);
        \draw (E2) -- +(0cm, -1.5cm) -- +(3cm,-1.5cm) -- (F3);
        \draw[arrows={-Stealth}] (F2) -- (G1) node[midway, left = 0.1cm]{\makecell{\small 克服EKF的缺点\\[-0.4em]\small 线性化误差和噪声高斯分布假设}};
        \draw[arrows={-Stealth}] (F3) -- (G2) node[midway, left = 0.1cm]{\small 代表优化技术};

        \begin{pgfonlayer}{background}
            \path (A.west |- A.north)+(-0.5,0.25) node (a1) {};
            \path (A.east |- A.south)+(+0.5,-0.25) node (a2) {}; 
            \path[fill=yellow!20,rounded corners, draw=black!50, dashed] (a1) rectangle (a2);
            \path (A.east |- A.south)+(3,1) node (u1)[draw, inner sep=5pt] {\large \textbf{SLAM 基本方程}};
        \end{pgfonlayer}

        \begin{pgfonlayer}{background}
            \path (D1.west |- B1.north)+(-0.5,0.25) node (a1) {};
            \path (D4.east |- D2.south)+(+0.5,-0.25) node (a2) {}; 
            \path[fill=yellow!20,rounded corners, draw=black!50, dashed] (a1) rectangle (a2);
            \path (D4.east |- B2.south)+(1.8,-0.8) node (u1)[draw, inner sep=5pt] {\large \textbf{参数化}};
        \end{pgfonlayer}

        \begin{pgfonlayer}{background}
            \path (E1.west |- E1.north)+(-0.3,0.25) node (a1) {};
            \path (F3.east |- G1.south)+(+0.3,-1.8) node (a2) {}; 
            \path[fill=yellow!20,rounded corners, draw=black!50, dashed] (a1) rectangle (a2);
        \end{pgfonlayer}

    \end{tikzpicture}
    \vspace*{-2.5em}
    \caption{SLAM 问题数学表述总结图}
    \label{SLAM Summary}
\end{figure}



